# Udacity--Capstone-Project

## Motivations
1. Learning PySpark Codes
2. Loading Data into Spark and doing diagonistis analytics to identify Feature variables
3. Using machine learning codes to identify the best model to deploy to identify churners

## DataSet

The dataset was provided by Udacity. Diagonistic was run on the small data set of 128 MB.Original Data set is of 12 GB. Due to limited 
computation power of the laptop the smaller data set was utilized

## Frameworks Needed to run the code
1. Pyspark SQL and PySpark ML Libraries
2. Matplotlib for ploting histograms
3. Pandas for basic data manipulation

## Summary of the project

The code contains the following sections

1. Data Cleaning
2. Data Exploration
3. Feature Engineering
4. Modelling

## Results: 

Logistic Regression and Random forest was run based on various hyperparameters. Random forest model is used as it has a better AUC score.

## Other Deliverables
The blog has been written on the findings of the project. The link is: https://medium.com/@shrivastava.tohan/playing-with-big-data-not-so-dirty-as-thought-so-bdacd9c6a3d5

## Acknowledgement

Data set was provided by Updatacity. PySpark codes was refered based on publicily available sources. 


